{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a77bb29-e890-498f-aff7-8206725e8347",
   "metadata": {},
   "source": [
    "# **Agentic AI - NBA Stats**\n",
    "## **Author:** Tanner Rapp\n",
    "### **Data Source:** Walsh, W. (n.d.). NBA Database [Data set]. Kaggle. https://www.kaggle.com/datasets/wyattowalsh/basketball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25c866-a1a1-4159-a514-8a328c1690d0",
   "metadata": {},
   "source": [
    "#### About this Program\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba640d0-01c7-481e-b42e-e0306e89ba3a",
   "metadata": {},
   "source": [
    "This program automates NBA data analysis using an “agentic” (autonomous) AI workflow. It connects to structured datasets—like player stats, draft history, or team performance—by uploading CSV files and allowing a GPT model (e.g., GPT-4.1-mini) with a code interpreter to read, query, and reason over them. The script first identifies which tables are relevant to the user’s question (for example, selecting draft_history when asked about Lakers’ recent draft picks), then executes Python code inside the model’s sandbox to explore and return structured outputs and analytical notes. Essentially, it’s a dynamic data-assistant pipeline that lets a model act as both analyst and coder for NBA-related data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb789a94-84cb-4ca4-8d57-987294e11222",
   "metadata": {},
   "source": [
    "#### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff34be4b-3e28-47b9-abb5-3107bf5e1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98b7b8-c9d6-4371-ab83-a947ea55a8d6",
   "metadata": {},
   "source": [
    "#### Download Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378c7b44-176e-47bf-9e50-50a1e6463711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists\n"
     ]
    }
   ],
   "source": [
    "sample_file = os.path.join(os.getcwd(),\"csv\", \"game.csv\")\n",
    "\n",
    "if not os.path.exists(sample_file):\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files('wyattowalsh/basketball', path='.', unzip=True)\n",
    "else:\n",
    "    print(\"Dataset already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b3b59f-db2b-4ca7-8605-b8a16d4b0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available data from the Kaggle source\n",
    "tables = [\n",
    "    \"common_player_info\",\n",
    "    \"draft_combine_stats\",\n",
    "    \"draft_history\",\n",
    "    \"game\",\n",
    "    \"game_info\",\n",
    "    \"game_summary\",\n",
    "    \"inactive_players\",\n",
    "    \"line_score\",\n",
    "    \"officials\",\n",
    "    \"other_stats\",\n",
    "    \"play_by_play\",\n",
    "    \"player\",\n",
    "    \"team\",\n",
    "    \"team_details\",\n",
    "    \"team_history\",\n",
    "    \"team_info_common\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8aca1c2-c723-4562-a919-3552c897ce5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded common_player_info.csv — shape: (4171, 33)\n",
      "✅ Loaded draft_combine_stats.csv — shape: (1202, 47)\n",
      "✅ Loaded draft_history.csv — shape: (7990, 14)\n",
      "✅ Loaded game.csv — shape: (65698, 55)\n",
      "✅ Loaded game_info.csv — shape: (58053, 4)\n",
      "✅ Loaded game_summary.csv — shape: (58110, 14)\n",
      "✅ Loaded inactive_players.csv — shape: (110191, 9)\n",
      "✅ Loaded line_score.csv — shape: (58053, 43)\n",
      "✅ Loaded officials.csv — shape: (70971, 5)\n",
      "✅ Loaded other_stats.csv — shape: (28271, 26)\n",
      "✅ Loaded play_by_play.csv — shape: (13592899, 34)\n",
      "✅ Loaded player.csv — shape: (4831, 5)\n",
      "✅ Loaded team.csv — shape: (30, 7)\n",
      "✅ Loaded team_details.csv — shape: (25, 14)\n",
      "✅ Loaded team_history.csv — shape: (52, 5)\n",
      "✅ Loaded team_info_common.csv — shape: (0, 26)\n"
     ]
    }
   ],
   "source": [
    "#Loading in the data\n",
    "dfs = {}\n",
    "for name in tables:\n",
    "    file_path = os.path.join(os.getcwd(), \"csv\", f\"{name}.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs[name] = df\n",
    "        print(f\"✅ Loaded {name}.csv — shape: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"⚠️ File not found: {name}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f199b-a34b-452a-8311-72c8daf983d3",
   "metadata": {},
   "source": [
    "#### Upload Files to OpeanAI Assistants \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a5ec91-52f0-4d54-9279-72d205b2fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open OpenAI Client through an API key\n",
    "load_dotenv(\".env\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a63cb8-7ee2-4329-b70a-91e723fa5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), \"csv\")\n",
    "\n",
    "# Collect all CSVs you want the analyst to see\n",
    "csv_paths = glob.glob(os.path.join(DATA_DIR, \"*.csv\"))\n",
    "assert csv_paths, f\"No CSVs found in {DATA_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607a287c-7865-459e-95bd-eab85569e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload them to OpenAI Files (purpose='assistants')\n",
    "uploaded_files = []\n",
    "for p in csv_paths:\n",
    "    if os.path.basename(p) == \"play_by_play.csv\":\n",
    "        continue # Have to skip this dataset because it is way too big to be uploaded (exceeded openai's limit)\n",
    "        \n",
    "    f = client.files.create(file=open(p, \"rb\"), purpose=\"assistants\")\n",
    "    uploaded_files.append({\"name\": os.path.basename(p), \"id\": f.id})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5121f60a-d5b7-4b03-8026-df84007d55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content=[]\n",
    "for f in uploaded_files:\n",
    "    user_content.append({\"name\": f['name'], \"file_id\": f[\"id\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbfd2f4-4584-4ad5-bd3d-13a1df5be73e",
   "metadata": {},
   "source": [
    "#### Config You Control\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "203e606e-8769-4ef6-a62d-6316b629f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_QUERY = \"Who did the lakers draft most recentl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd9dac-2739-4ee4-8022-da62280884f1",
   "metadata": {},
   "source": [
    "#### Define AI Agent Roles\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd0a927-29cb-487b-99ec-77b951cd6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIER_SYS = (\n",
    "        \"You read the user's query and decide which tables are needed. \"\n",
    "        \"Prefer the smallest set of tables that can fully answer the question. \"\n",
    "        \"For player game totals by game, favor 'game', 'game_summary', and 'player' (for IDs). \"\n",
    "        \"Return your decision by calling select_tables().\"\n",
    ")\n",
    "ANALYST_SYS = (\n",
    "        \"You have Python via the code_interpreter tool. \"\n",
    "        \"Goal: given a user query and a list of relevant tables, load the CSVs from DATA_DIR, \"\n",
    "        \"locate the player (e.g., LeBron James), identify the latest full season ('last season'), \"\n",
    "        \"and return a concise table of game-level totals (one row per game) including date, opponent, \"\n",
    "        \"and key box score totals (points, rebounds, assists, etc.). Print the final dataframe head(10). \"\n",
    "        \"If a needed file is missing, clearly state which is missing.\"\n",
    ")\n",
    "WRITER_SYS =  ( \n",
    "        \"Turn analytic output into a short, clear paragraph. \"\n",
    "        \"Summarize what was computed and highlight key takeaways. Keep it factual and concise.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3a876-6b6b-4457-a3ff-f3a623eeaa33",
   "metadata": {},
   "source": [
    "#### Run Agent 1: Table Identifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2b1b63c-e91c-442a-8d6c-2348adc918f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ANALYST OUTPUT ---\n",
      " I can access the files through python.\n",
      "\n",
      "- Use draft_history to find the most recent Lakers draft picks.\n",
      "- Use team to confirm Lakers team ID if needed for filtering.\n"
     ]
    }
   ],
   "source": [
    "id_resp = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=[{\"type\": \"code_interpreter\",\n",
    "           \"container\": { \"type\": \"auto\", \"file_ids\": [f[\"file_id\"] for f in user_content] }}],\n",
    "    input=[\n",
    "        {\"role\":\"system\",\"content\":IDENTIFIER_SYS},\n",
    "        {\"role\":\"user\",\"content\":\n",
    "         f\"USER QUERY: {USER_QUERY}\\n\"\n",
    "         \"\\n\\nTABLE_DESCRIPTIONS (JSON):\\n\"+json.dumps(table_descriptions, indent=2)+\n",
    "         \"\\n\\nYou can use python to look through each dataset from file_ids in user content for actual columns to identify what is needed to answer the user query.\"\n",
    "         \"n\\n\\Confirm if you can access the files through python with a simple statement saying that you can or can't\"\n",
    "         \"n\\n\\Keep is super short to which tables you will use and why in a bullet point format. Nothing else except if you can read the python files\"\n",
    "         \"n\\n\\Keep it to under 30 words.\"\n",
    "        }\n",
    "    ],\n",
    "    include=[\"code_interpreter_call.outputs\"] \n",
    ")\n",
    "\n",
    "print(\"\\n--- ANALYST OUTPUT ---\\n\", id_resp.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16656ec-990f-4da9-9371-34c0ca0ed474",
   "metadata": {},
   "source": [
    "#### Run Agent 2: Data Analyst\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c766c7a7-44b2-4ab3-ae1f-c474c11513bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ANALYST OUTPUT ---\n",
      " Let's follow your instructions step-by-step:\n",
      "\n",
      "### 1. Relevant files:\n",
      "- `draft_history.csv` — needed to find recent Lakers draft picks.\n",
      "- `team.csv` — useful to determine the Lakers' team ID.\n",
      "- (We don't need other tables for just the most recent draft pick.)\n",
      "\n",
      "Let's load these files and proceed with the task: \n",
      "- Find the Lakers' team ID from `team.csv`.\n",
      "- Use this team ID to filter `draft_history.csv` for Lakers picks.\n",
      "- Find the most recent draft pick(s).\n",
      "- Output a concise DataFrame (top 10 if more than one).\n",
      "\n",
      "Let me start by loading the relevant files and inspecting them.- The `team.csv` file uses `id` for team ID and `full_name` for team name.\n",
      "- The `draft_history.csv` uses `team_id` for which team made the pick; `player_name`, `season`, etc. are for the draft pick.\n",
      "\n",
      "Let's:\n",
      "1. Find the Lakers' team ID (`full_name` contains 'Lakers').\n",
      "2. Filter `draft_history.csv` rows where `team_id` is the Lakers.\n",
      "3. Find the latest (`season` max) pick(s).\n",
      "4. Display a concise DataFrame: player name, season, round, pick, overall pick, organization.\n",
      "\n",
      "Let's do this.Here are the most recent draft picks made by the Lakers (season 2023):\n",
      "\n",
      "|      player_name        | season | round_number | round_pick | overall_pick |   organization        |\n",
      "|------------------------|--------|--------------|------------|--------------|-----------------------|\n",
      "| Jalen Hood-Schifino    | 2023   |      1       |     17     |      17      | Indiana               |\n",
      "| Mojave King            | 2023   |      2       |     17     |      47      | Ignite (G League)     |\n",
      "\n",
      "**These are the most recent players drafted by the Lakers, based on the available data.**\n"
     ]
    }
   ],
   "source": [
    "analyst_resp = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\"type\": \"code_interpreter\",\n",
    "           \"container\": { \"type\": \"auto\", \"file_ids\": [f[\"file_id\"] for f in user_content] }}],\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"input_text\", \"text\": ANALYST_SYS}]},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\":\n",
    "                \"Here is the task and context:\\n\"\n",
    "                f\"- User query: {USER_QUERY}\\n\"\n",
    "                \"INSTRUCTIONS:\\n\"\n",
    "                \"1) Use Python to read/analyze necessary CSVs from the attached files.\\n\"\n",
    "                f\"2) Identify relevant tables and columns from {id_resp.output_text}.\\n\"\n",
    "                \"3) Resolve player/team IDs if needed.\\n\"\n",
    "                \"4) Filter/join/aggregate as required.\\n\"\n",
    "                \"5) Show a concise DataFrame and head(10).\\n\"\n",
    "                \"6) If a file/column is missing, state which and continue.\"\n",
    "                \"7) Regardless of whether or not you have all you need, just compute what you can with what is given from chosen_tables. You must return some stats\"\n",
    "            }\n",
    "        ]}\n",
    "    ],\n",
    "    include=[\"code_interpreter_call.outputs\"] \n",
    ")\n",
    "\n",
    "print(\"\\n--- ANALYST OUTPUT ---\\n\", analyst_resp.output_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a0bc9-d7a2-4e81-8b0f-0402fa84aa0e",
   "metadata": {},
   "source": [
    "#### Run Agent 3: Writer\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cbeeb81-ad84-4668-ad91-ecd112fc8c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WRITER OUTPUT ---\n",
      " The analysis identified the Los Angeles Lakers' team ID from the `team.csv` file and used it to filter the `draft_history.csv` data for the most recent draft picks. The latest season for draft picks is 2023, and the most recent Lakers draft picks are Jalen Hood-Schifino (1st round, 17th overall) and Mojave King (2nd round, 47th overall). These players represent the Lakers' newest additions based on the available draft history.\n",
      "\n",
      "|      player_name        | season | round_number | round_pick | overall_pick |   organization        |\n",
      "|------------------------|--------|--------------|------------|--------------|-----------------------|\n",
      "| Jalen Hood-Schifino    | 2023   |      1       |     17     |      17      | Indiana               |\n",
      "| Mojave King            | 2023   |      2       |     17     |      47      | Ignite (G League)     |\n"
     ]
    }
   ],
   "source": [
    "writer_resp = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[\n",
    "        {\"role\":\"system\",\"content\":WRITER_SYS},\n",
    "        {\"role\":\"user\",\"content\":\"Turn this into a short summary:\\n\\n\"+analyst_resp.output_text+\"\\n\\n\"+\n",
    "        \"You must show any tables from the analyst_resp.output_text to go along with your response\"}\n",
    "    ]\n",
    ")\n",
    "print(\"\\n--- WRITER OUTPUT ---\\n\", writer_resp.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
