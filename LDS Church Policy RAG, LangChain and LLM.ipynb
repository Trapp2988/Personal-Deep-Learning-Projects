{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86016667-1275-4c62-9b5b-7ac88cf0854f",
   "metadata": {},
   "source": [
    "# **LDS Church Policy Handbook RAG, LangChain and LLM**\n",
    "## **Author:** Tanner Rapp\n",
    "### **Policy Source:** https://www.churchofjesuschrist.org/study/manual/general-handbook?lang=eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c02c1-f4f3-480a-803f-89bd8487e3c6",
   "metadata": {},
   "source": [
    "### About this Program\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0994f537-35fb-472b-9dcc-de9a926090d1",
   "metadata": {},
   "source": [
    "This script builds a small RAG (retrieval-augmented generation) app for the LDS General Handbook. It loads the PDF, splits it into ~2k-char chunks, turns those chunks into embeddings with intfloat/e5-base-v2, and stores/loads them in a FAISS vector index for fast semantic search. It configures an OpenAI chat model with a strict prompt (“answer only from context; otherwise say ‘I don’t know’”) and wraps search + generation in a ConversationalRetrievalChain with short chat memory. You can query it in a CLI loop or via a minimal Flask web app (/ask) that returns the answer plus up to 5 source snippets (page labels included). API keys are pulled from a local .env, and the FAISS index is cached to avoid rebuilding on every run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc0aa3-7387-435e-8737-428185ef4023",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09acd690-c590-4e58-ae34-fbb75c4e1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import os\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0205bb6f-9f68-4209-a442-e0b3f5fd71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\tanne\\Church Policy RAG\") #Only run if locally for finding api key!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01483223-48a2-4e00-b142-f66d7dd248d1",
   "metadata": {},
   "source": [
    "### Load the Policy PDF\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c10434b-ef29-4ca4-a831-97d34e8b61f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 468 pages.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r\"C:\\Users\\tanne\\Church Policy RAG\\general_handbook_serving_in_the_church_of_jesus_christ_of_latter_day_saints.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()\n",
    "print(f\"✅ Loaded {len(pages)} pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114a5320-b76f-4eee-a4cd-b637c5de805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='August 2024  |  1\n",
      "0.\n",
      "Introductory Overview\n",
      "0.0\n",
      "Introduction\n",
      "The Lord taught, “Let every man learn his duty, and \n",
      "to act in the office in which he is appointed, in all \n",
      "diligence” (Doctrine and Covenants 107:99). As a \n",
      "leader in The Church of Jesus Christ of Latter-day \n",
      "Saints, you should seek personal revelation to help \n",
      "you learn and fulfill the duties of your calling.\n",
      "Studying the scriptures and the teachings of latter-\n",
      "day prophets will help you understand and fulfill \n",
      "your duties. As you study the words of God, you  \n",
      "will be more receptive to the influence of the Spirit \n",
      "(see Doctrine and Covenants 84:85).\n",
      "Y ou also learn your duties by studying the instruc-\n",
      "tions in this handbook. These instructions can invite \n",
      "revelation if they are used to provide an understand-\n",
      "ing of principles, policies, and procedures to apply \n",
      "while seeking the guidance of the Spirit.\n",
      "0.1\n",
      "This Handbook\n",
      "General Handbook: Serving in The Church of Jesus Christ \n",
      "of Latter-day Saints provides guidance for general and \n",
      "local Church leaders. It is divided into sections:\n",
      "• Doctrinal Foundation: These chapters present doc-\n",
      "trine and principles fundamental to serving in the \n",
      "Church. They explain:\n",
      "◦ God’s plan of happiness, His work of salvation \n",
      "and exaltation, and the purpose of the Church.\n",
      "◦ The role of the family in God’s plan, His work \n",
      "of salvation and exaltation in the home, and \n",
      "the relationship between the home and the  \n",
      "Church.\n",
      "◦ Priesthood principles.\n",
      "◦ Principles for leading in the Savior’s Church.\n",
      "• Church Organization: These chapters provide \n",
      "instructions for stake presidencies and bishop-\n",
      "rics, priesthood quorum leaders, stake and ward \n",
      "organization leaders, and others who serve in \n",
      "the Church.\n",
      "• God’s Work of Salvation and Exaltation: These chap-\n",
      "ters instruct on the core work of the Church:\n",
      "◦ Living the gospel of Jesus Christ\n",
      "◦ Caring for those in need\n",
      "◦ Inviting all to receive the gospel\n",
      "◦ Uniting families for eternity\n",
      "• Church Administration: These chapters present  \n",
      "additional guidelines for administering the \n",
      "Church. Subjects include meetings, callings, \n",
      "records, finances, and policies.\n",
      "The headings and subheadings in this handbook are \n",
      "numbered to make topics easy to find and reference. \n",
      "For example, instruction about who may be sealed  \n",
      "in a temple is provided in 27.3.1. The number 27  \n",
      "refers to the chapter, the number 3 refers to a sec-\n",
      "tion in that chapter, and the number 1 refers to a \n",
      "subsection.\n",
      "0.2\n",
      "Adaptation and \n",
      "Optional Resources\n",
      "Not all stakes and wards have the same needs. This \n",
      "handbook contains guidelines for adaptation as well \n",
      "as optional resources:' metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.4 (Macintosh)', 'creationdate': '2024-09-06T08:21:26-06:00', 'moddate': '2024-09-06T08:47:29-06:00', 'trapped': '/False', 'source': 'C:\\\\Users\\\\tanne\\\\Church Policy RAG\\\\general_handbook_serving_in_the_church_of_jesus_christ_of_latter_day_saints.pdf', 'total_pages': 468, 'page': 17, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Showing Introduction from the General Handbook\n",
    "print(pages[17])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83da2fb-9fd3-490b-9d82-bf908670883d",
   "metadata": {},
   "source": [
    "### Split\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4a5a89-e14b-4095-9beb-e080f86ff1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]) # The splitter goes down the list in order — it first tries to split on paragraph breaks (\\n\\n), \n",
    "                                        # then line breaks (\\n), then spaces ( ), and finally anywhere (\"\") if needed.\n",
    "\n",
    "chunks = splitter.split_documents(pages)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e54bf7d-63c4-44b3-8c03-e2ee48ac4e32",
   "metadata": {},
   "source": [
    "### Embed & Store\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f302e6ea-c574-49c3-ba3e-c21774e4eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tanne\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the embedding model — converts each text chunk into a numerical embedding used for semantic similarity search in RAG.\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/e5-base-v2\",  # Model turns text chunks into numeric vectors so you can search for relevant content.\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58d086d-365c-4d5c-9190-48b8631d38d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing FAISS index.\n"
     ]
    }
   ],
   "source": [
    "#Save into vector database or load FAISS index ---- \n",
    "index_dir = \"faiss_index\"\n",
    "\n",
    "if os.path.exists(index_dir):\n",
    "    vectordb = FAISS.load_local(index_dir, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Loaded existing FAISS index.\")\n",
    "else:\n",
    "    vectordb = FAISS.from_documents(chunks, embeddings)\n",
    "    vectordb.save_local(index_dir)\n",
    "    print(f\"Built and saved FAISS index with {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a5e093-c4e2-4701-8b31-8ff9451e8fcf",
   "metadata": {},
   "source": [
    "### LLM Construction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645cb183-a752-4359-99bd-c82aebd0a016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV exists: True -> C:\\Users\\tanne\\Church Policy RAG\\.env\n",
      "First 4 bytes: b'\\xef\\xbb\\xbfO'\n",
      "Text preview:\n",
      " ﻿OPENAI_API_KEY=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\n",
      "\n",
      "dotenv_values: OrderedDict({'\\ufeffOPENAI_API_KEY': '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'})\n",
      "load_dotenv returned: True\n",
      "OPENAI_API_KEY -> None\n"
     ]
    }
   ],
   "source": [
    "env_path = Path(r\"C:\\Users\\tanne\\Church Policy RAG\\.env\")\n",
    "print(\"ENV exists:\", env_path.exists(), \"->\", env_path)\n",
    "\n",
    "if env_path.exists():\n",
    "    print(\"First 4 bytes:\", env_path.read_bytes()[:4])\n",
    "    try:\n",
    "        print(\"Text preview:\\n\", env_path.read_text(encoding=\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(\"UTF-8 read error:\", e)\n",
    "\n",
    "print(\"dotenv_values:\", dotenv_values(dotenv_path=env_path, encoding=\"utf-8\"))\n",
    "\n",
    "loaded = load_dotenv(dotenv_path=env_path, override=True, encoding=\"utf-8\")\n",
    "print(\"load_dotenv returned:\", loaded)\n",
    "print(\"OPENAI_API_KEY ->\", os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c34bad-b049-483f-a7ca-f3bf6abc5015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing API Key from local storage\n",
    "load_dotenv(encoding=\"utf-8-sig\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7faa39df-d7b4-4dbf-ae61-426cb18cc640",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",     \n",
    "    temperature=0.3,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\") \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef13df56-8fb2-42d2-80ab-cecd5bbb1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "prompt_template = \"\"\"\n",
    "You are a careful and respectful assistant helping interpret official LDS Church policy materials.\n",
    "Use only the information in the provided context to answer the question.\n",
    "If the answer is not clearly supported by the document, reply: \"I don't know.\"\n",
    "\n",
    "### Guidelines\n",
    "- Base all answers strictly on the context. Do not speculate, infer doctrine, or give personal interpretation.\n",
    "- When quoting or paraphrasing, maintain the respectful and neutral tone of official Church communications.\n",
    "- If multiple sources or policies differ, summarize each faithfully without assuming which is \"correct.\"\n",
    "- Avoid doctrinal commentary, personal opinion, or speculation about Church leaders’ intent.\n",
    "- When unsure, encourage the user to consult the official Handbook or local priesthood leadership for clarification.\n",
    "\n",
    "### Output\n",
    "Provide a concise, respectful answer in 1–4 sentences.\n",
    "If appropriate, include a short bullet list summarizing key points or policy steps.\n",
    "\n",
    "### Context\n",
    "{context}\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3b0219-012b-4822-9cbd-56fc6199242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanne\\AppData\\Local\\Temp\\ipykernel_22092\\2966180864.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "# Give the chatbot a memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key = \"chat_history\", \n",
    "    return_messages = True,\n",
    "    output_key=\"answer\" )\n",
    "\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d663e62-ae76-4ad0-b29f-542733eaa077",
   "metadata": {},
   "outputs": [],
   "source": [
    "crc = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": PROMPT}  # your LDS policy prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6203d3-6ae6-4cc9-b6e1-edfde6f8efd2",
   "metadata": {},
   "source": [
    "### Retrevial & Generation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4778cafc-4af8-49e7-950e-39655636e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt():\n",
    "    while True:\n",
    "        query = input(\"Ask a question about LDS Church Policy:  \").strip()\n",
    "\n",
    "        # Exit conditions\n",
    "        if query.lower() in ['exit', 'bye','goodbye']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Run query through your retrieval chain\n",
    "        response = crc.invoke({\"question\": query}, {\"chat_history\": history})\n",
    "\n",
    "        # Print results safely\n",
    "        print(\"\\n\\n---------------------------------------------------------------------------------\\n\\n\", response['answer'])\n",
    "        print(\"\\nSource Page #: \",\n",
    "            response['source_documents'][0].metadata.get('page_label', 'N/A'),\n",
    "            \"  ⬇️ See below.\"\n",
    "        )\n",
    "        print(\"\\nSource: \", response['source_documents'][0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0dff995-27ba-4875-b7f0-5c4a238d8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter a prompt! \n",
    "#prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7daf816-35f1-4c66-8280-fb81443a7859",
   "metadata": {},
   "source": [
    "### Web Interface\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d601f470-03e6-4761-a1ea-885bc1a754af",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/ask\", methods=[\"POST\"])\n",
    "def ask():\n",
    "    payload = request.get_json(force=True) or {}\n",
    "    question = (payload.get(\"question\") or \"\").strip()\n",
    "    if not question:\n",
    "        return jsonify({\"error\": \"Empty question\"}), 400\n",
    "\n",
    "    # No history: invoke the chain fresh each time\n",
    "    res = crc.invoke({\"question\": question})\n",
    "    answer = (res.get(\"answer\") or res.get(\"result\") or \"\").strip()\n",
    "\n",
    "    sources = []\n",
    "    for d in (res.get(\"source_documents\") or [])[:5]:\n",
    "        m = getattr(d, \"metadata\", {}) or {}\n",
    "        sources.append({\n",
    "            \"source\": m.get(\"source\") or m.get(\"file_path\") or m.get(\"url\") or \"Unknown\",\n",
    "            \"page_label\": str(m.get(\"page_label\", m.get(\"page\", \"N/A\"))),\n",
    "            \"snippet\": (getattr(d, \"page_content\", \"\") or \"\")[:600],\n",
    "        })\n",
    "\n",
    "    return jsonify({\"answer\": answer, \"sources\": sources})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c1f3f19-8617-44a4-8617-593a4811167a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Oct/2025 11:10:02] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Oct/2025 11:10:05] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/Oct/2025 11:10:35] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Oct/2025 11:11:23] \"POST /ask HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Run only if locally\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"127.0.0.1\", port=5000, debug=False, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
